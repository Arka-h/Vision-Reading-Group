
# Vision-Reading-Group
Stay upto date with recent papers in the field!

## Table of Contents
- [Vision-Reading-Group](#vision-reading-group)
  - [Table of Contents](#table-of-contents)
- [Research Papers](#research-papers)
  - [3D Vision](#3d-vision)
    - [3D Generation](#3d-generation)
    - [3D Editing](#3d-editing)
    - [3D Grounding](#3d-grounding)
    - [3D Inpainting](#3d-inpainting)
    - [NERFs](#nerfs)
  - [Diffusion](#diffusion)
- [Survey Papers](#survey-papers)
  - [3D Vision](#3d-vision-1)
    - [NERFs](#nerfs-1)
    - [Emboidied AI](#emboidied-ai)

# Research Papers
## 3D Vision
### 3D Generation
- [x] LucidDreaming: Controllable Object-Centric 3D Generation [Submitted 30 Nov 2023 arxiv] [[Paper](https://arxiv.org/abs/2312.00588)] [[Demo](https://www.zhaoningwang.com/LucidDreaming/)] [[Code](https://github.com/EricWang12/LucidDreaming/tree/main)]
- [ ] HD-Fusion: Detailed Text-to-3D Generation Leveraging Multiple Noise Estimation [WACV 24] [[Paper](https://arxiv.org/abs/2307.16183)] [[Video](https://www.youtube.com/watch?v=3uPFCCaTIcQ)]
### 3D Editing
- [Awesome NERF editing](https://github.com/EricLee0224/awesome-nerf-editing)
- [x] GaussianEditor: Swift and Controllable 3D Editing with Gaussian Splatting [Submitted 24 Nov 2023 arxiv] [[Paper](https://arxiv.org/abs/2311.14521)] [[Demo](https://buaacyw.github.io/gaussian-editor/)] [[Code](https://github.com/buaacyw/GaussianEditor)] [[Video](https://www.youtube.com/watch?v=TdZIICSFqsU)]
- [ ] *Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions [ICCV 23] [[Paper](https://arxiv.org/abs/2303.12789)] [[Demo](https://instruct-nerf2nerf.github.io/)] [[Code](https://github.com/ayaanzhaque/instruct-nerf2nerf)]
- [ ] ED-NeRF: Efficient Text-Guided Editing of 3D Scene With Latent Space NeRF [ICLR 24] [[Paper](https://arxiv.org/abs/2310.02712)] [[Demo](https://ed-nerf.github.io/)] 
- [ ] Sketch and Text Guided Diffusion Model for Colored Point Cloud Generation [ICCV 23] [[Paper](https://arxiv.org/abs/2308.02874)]
- [ ] DreamBooth3D: Subject-Driven Text-to-3D Generation [ICCV 23] [[Paper](https://arxiv.org/abs/2303.13508)] [[Demo](https://dreambooth3d.github.io/)] 
- [ ] Vox-E: Text-guided Voxel Editing of 3D Objects [ICCV 23] [[Paper](https://arxiv.org/abs/2303.12048)] [[Demo](https://tau-vailab.github.io/Vox-E/)] [[Code](https://github.com/TAU-VAILab/Vox-E)]
- [ ] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields [CVPR 22] [[Paper](https://arxiv.org/abs/2112.05139)] [[Demo](https://cassiepython.github.io/clipnerf/)] [[Code](https://github.com/cassiePython/CLIPNeRF)]
- [ ] DreamEditor: Text-Driven 3D Scene Editing with Neural Fields [SIGGRAPH 23] [[Paper](https://arxiv.org/abs/2306.13455)] [[Demo](https://www.sysu-hcp.net/projects/cv/111.html)] [[Code](https://github.com/zjy526223908/DreamEditor)] 
- [ ] 3D-FM GAN: Towards 3D-Controllable Face Manipulation [ECCV 22] [[Paper](https://arxiv.org/abs/2208.11257)] [[Demo](https://lychenyoko.github.io/3D-FM-GAN-Webpage/)] [[Code](https://github.com/adobe/3D-FM-GAN)]
### 3D Grounding
- [ ] Language Conditioned Spatial Relation Reasoning for 3D Object Grounding [NerIPS 22] [[Paper](https://arxiv.org/abs/2211.09646)] [[Demo](https://cshizhe.github.io/projects/vil3dref.html)] [[Code](https://github.com/cshizhe/vil3dref)]
- [ ] 3D Concept Grounding on Neural Fields [NeurIPS 22] [[Paper](https://arxiv.org/abs/2207.06403)] [[Code](https://github.com/evelinehong/3D-Concept-Grounding)]
- [ ] LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent [Submitted ICRA 2024] [[Paper](https://arxiv.org/abs/2309.12311)][[Demo](https://chat-with-nerf.github.io/)] [[Code](https://github.com/sled-group/chat-with-nerf)]
- [ ] Multi-View Transformer for 3D Visual Grounding [CVPR 22] [[Paper](https://arxiv.org/abs/2204.02174)] [[Code](https://github.com/sega-hsj/MVT-3DVG)]
### 3D Inpainting
- [ ] Breathing New Life into 3D Assets with Generative Repainting [ICCV 23] [[Paper](https://arxiv.org/abs/2309.08523)] [[Demo](https://www.obukhov.ai/repainting_3d_assets)] [[Code](https://github.com/kongdai123/repainting_3d_assets)]
- [ ] RePaint: Inpainting using Denoising Diffusion Probabilistic Models [CVPR 22] [[Paper](https://arxiv.org/abs/2201.09865)] [[Code](https://github.com/andreas128/RePaint)]
- [ ] DreamFusion: Text-to-3D using 2D Diffusion [ICLR 23] [[Paper](https://arxiv.org/abs/2209.14988)] [[Demo](https://dreamfusion3d.github.io/)]
- [ ] Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data [Submitted 2 Jan 23 arxiv] [[Paper](https://arxiv.org/abs/2301.00527)] [[Code](https://github.com/zoomin-lee/scene-scale-diffusion)]
### NERFs
- [x] D-NeRF: Neural Radiance Fields for Dynamic Scenes [CVPR 21] [[Paper](https://arxiv.org/abs/2011.13961)] [[Demo](https://www.albertpumarola.com/research/D-NeRF/index.html)] [[Code](https://github.com/albertpumarola/D-NeRF)]
- [x] Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields [ICCV 21] [[Paper](https://arxiv.org/abs/2103.13415)] [[Code](https://github.com/google/mipnerf)]

## Diffusion
- [ ] LatentPaint: Image Inpainting in Latent Space with Diffusion Models [WACV 24] [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Corneanu_LatentPaint_Image_Inpainting_in_Latent_Space_With_Diffusion_Models_WACV_2024_paper.pdf)] [[Video](https://www.youtube.com/watch?v=mhHc34O2H4o)]
- [ ] DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation [CVPR 23] [[Paper](https://arxiv.org/abs/2208.12242)] [[Demo](https://dreambooth.github.io/)] [[Dataset](https://github.com/google/dreambooth)] [[Tutorial](https://huggingface.co/docs/diffusers/en/training/dreambooth)]

# Survey Papers
## 3D Vision
### NERFs
- [ ] NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review [Submitted 30 Nov arxiv] [[Paper](https://arxiv.org/abs/2210.00379)]
### Emboidied AI
- [ ] A Survey of Embodied AI: From Simulators to Research Tasks [IEEE Txn 22] [[Paper](https://arxiv.org/abs/2103.04918)]
